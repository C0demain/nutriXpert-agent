
# nutriXpert-agent

## üìå Descri√ß√£o

O **nutriXpert-agent** √© um agente conversacional desenvolvido em **Python + FastAPI**, como parte do projeto do 6¬∫ semestre de **An√°lise e Desenvolvimento de Sistemas**.
Ele responde perguntas relacionadas √† **nutri√ß√£o, h√°bitos alimentares e composi√ß√£o nutricional de alimentos**, utilizando **RAG (Retrieval-Augmented Generation)** para enriquecer suas respostas com base em documentos locais (ex.: PDFs e planilhas TACO).

---

## ‚öôÔ∏è Pr√©-requisitos

* **Python 3.10+**
* **PostgreSQL** (ou outro banco compat√≠vel, configurado via `DATABASE_URL`)
* (Opcional) **Docker** para containeriza√ß√£o
* (Opcional) **Ollama** para rodar modelos locais, como o **MedGemma**

---

## üöÄ Como rodar o projeto

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/SEU_USUARIO/nutriXpert-agent.git
cd nutriXpert-agent
```

### 2. Criar ambiente virtual

```bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

### 3. Instalar depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Iniciar o servidor local

```bash
uvicorn main:app --reload --host 127.0.0.1 --port 8000
```

### Executar ADK Web UI para testes
```bash
adk web
```

O projeto estar√° acess√≠vel em:
üìç **Swagger UI:** [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
üìç **Redoc:** [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

---

## üê≥ Utilizando Docker (opcional)

Se preferir rodar via containers:

```bash
docker-compose up --build
```

---

## üîë Vari√°veis de ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes configura√ß√µes:

```ini
# Google API (opcional para usar modelos Gemini)
GOOGLE_GENAI_USE_VERTEXAI=FALSE
GOOGLE_API_KEY=YOUR_API_KEY

# Configura√ß√£o do FastAPI
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
UVICORN_RELOAD=true

# Configura√ß√£o do agente
ADK_APP_NAME=nutriXpert
DATABASE_URL=postgresql+psycopg2://myuser:mypassword@localhost:5432/mydb
ADK_MODEL=gemini-2.0-flash   # ou "ollama_chat/medgemma-4b" se usar via Ollama
ADK_SERIALIZE_RUNNER=false
```

üîó Sua API Key do Google pode ser gerada em: [Google AI Studio](https://aistudio.google.com/app/apikey).
üí° O modelo padr√£o √© o **Gemini 2.0 Flash**, gratuito no plano b√°sico do Google AI Studio.

---

## üß† Implementa√ß√£o do RAG

1. **Ingest√£o de documentos**

   * Arquivos PDF e XLSX devem ser colocados na pasta `documents/`.
   * A ingest√£o ocorre automaticamente no primeiro startup.

2. **Vetoriza√ß√£o**

   * O conte√∫do √© dividido em *chunks* pelo `RecursiveCharacterTextSplitter`.
   * Os embeddings s√£o gerados com **HuggingFace (sentence-transformers/all-MiniLM-L6-v2)**.

3. **Armazenamento**

   * Os vetores s√£o persistidos no **ChromaDB** (pasta `chroma_store/`).

4. **Recupera√ß√£o (Retriever)**

   * Ao receber uma pergunta, o agente busca os *chunks* mais relevantes no ChromaDB.
   * O contexto recuperado √© injetado antes da resposta final do modelo.

---

## üß© Usando o MedGemma via Ollama

Se preferir rodar o agente com o **MedGemma** localmente:

1. **Instalar o Ollama**
   Baixe em: [https://ollama.com/download](https://ollama.com/download)
   Verifique a instala√ß√£o:

   ```bash
   ollama --version
   ```

2. **Usar um Modelfile**
   Na raiz do projeto, certifique que existe o arquivo chamado `Modelfile` com o conte√∫do:

   ```dockerfile
   FROM hf.co/unsloth/medgemma-4b-it-GGUF:Q4_K_M
   ```

   Esse comando usa a vers√£o quantizada Q4_K_M publicada no Hugging Face.

3. **Registrar o modelo no Ollama**

   ```bash
   ollama create medgemma-4b -f Modelfile
   ```

   Confirme se foi criado:

   ```bash
   ollama list
   ```

4. **Executar o modelo diretamente** (teste opcional):

   ```bash
   ollama run medgemma-4b
   ```

5. **Configurar o agente para usar o MedGemma**
   No arquivo `.env`, altere a linha do modelo para:

   ```ini
   ADK_MODEL=ollama_chat/medgemma-4b
   ```

Agora o NutriXpert rodar√° utilizando o **MedGemma** local via Ollama.

---

## Observa√ß√µes

* Se quiser rodar com **Gemini** (default), mantenha `ADK_MODEL=gemini-2.0-flash`.
* Se quiser rodar com **MedGemma**, precisa do **Ollama** instalado e do **Modelfile** configurado.
* Se os documentos forem alterados, √© necess√°rio **deletar a pasta `chroma_store/`** e reiniciar a aplica√ß√£o para regenerar os embeddings.

